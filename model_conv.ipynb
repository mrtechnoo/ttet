{"cells":[{"cell_type":"code","execution_count":null,"id":"18a82351","metadata":{"id":"18a82351"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import os"]},{"cell_type":"code","execution_count":null,"id":"0fb17e49","metadata":{"id":"0fb17e49"},"outputs":[],"source":["rm -rf \"/workspace/nvidia/triton_model_repository\""]},{"cell_type":"code","execution_count":null,"id":"7e04f8e6","metadata":{"id":"7e04f8e6"},"outputs":[],"source":["os.makedirs(\"./triton_model_repository/resnet50_torch/1\")\n","os.makedirs(\"./triton_model_repository/resnet50_onnx/1\")\n","os.makedirs(\"./triton_model_repository/resnet50_trt_fp32/1\")\n","os.makedirs(\"./triton_model_repository/resnet50_trt_fp16/1\")"]},{"cell_type":"code","execution_count":null,"id":"02435474","metadata":{"id":"02435474","outputId":"9f102eb3-7cd4-4e70-c757-b8d4aadefe8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/workspace/aitrainingandinference\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"id":"1b8424d2","metadata":{"id":"1b8424d2"},"outputs":[],"source":["#Parameters\n","BATCH_SIZE = 8\n","PY_MODEL_PATH = './resnet50_ddp.pt'\n","JIT_MODEL_PATH = './triton_model_repository/resnet50_torch/1/model.pt'\n","ONNX_MODEL_PATH = './triton_model_repository/resnet50_onnx/1/model.onnx'\n","TRT_MODEL_PATH = './triton_model_repository/resnet50_trt_fp32/1/model.plan'\n","TRT_MODEL_PATH_FP16 = './triton_model_repository/resnet50_trt_fp16/1/model.plan'\n","MODEL_NAME = 'resnet50'\n","NUM_CLASSES = 4\n","INPUT_SHAPE = (3, 224, 224)\n","CHANNEL_LAST = False"]},{"cell_type":"code","execution_count":null,"id":"e749594c","metadata":{"id":"e749594c"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""]},{"cell_type":"markdown","id":"083f30a0","metadata":{"id":"083f30a0"},"source":["## Load Pytorch Model"]},{"cell_type":"code","execution_count":null,"id":"1365f13e","metadata":{"id":"1365f13e","outputId":"1ceba559-d601-4c00-92d3-9d49d74ab8a6"},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=2048, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.3, inplace=False)\n","    (3): Linear(in_features=512, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model = models.resnet50(pretrained=False)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n","                        nn.ReLU(),\n","                        nn.Dropout(p=0.3),\n","                        nn.Linear(512,2))\n","\n","if CHANNEL_LAST:\n","    model = model.to(device, memory_format=torch.channels_last)\n","else:\n","    model = model.to(device)\n","model.load_state_dict(torch.load(PY_MODEL_PATH))\n","model.eval()"]},{"cell_type":"markdown","id":"38f94988","metadata":{"id":"38f94988"},"source":["# Export to TorchScript"]},{"cell_type":"code","execution_count":null,"id":"ac23bf02","metadata":{"id":"ac23bf02"},"outputs":[],"source":["if CHANNEL_LAST:\n","    example = torch.randn((BATCH_SIZE, *INPUT_SHAPE), dtype=torch.float32, device=device).to(memory_format=torch.channels_last)\n","else:\n","    example = torch.randn((BATCH_SIZE, *INPUT_SHAPE), dtype=torch.float32, device=device)\n","\n","script = torch.jit.trace(model, example)\n","script.save(JIT_MODEL_PATH)"]},{"cell_type":"markdown","id":"59a6293c","metadata":{"id":"59a6293c"},"source":["# Export to ONNX"]},{"cell_type":"code","execution_count":null,"id":"f23984c0","metadata":{"id":"f23984c0"},"outputs":[],"source":["if CHANNEL_LAST:\n","    x = torch.randn((1, *INPUT_SHAPE), dtype=torch.float32, device=device).to(memory_format=torch.channels_last)\n","else:\n","    x = torch.randn((1, *INPUT_SHAPE), dtype=torch.float32, device=device)\n","\n","torch.onnx.export(model,                       # model being run\n","                  x,                           # model input (or a tuple for multiple inputs)\n","                  ONNX_MODEL_PATH,             # Path to saved onnx model\n","                  export_params=True,          # store the trained parameter weights inside the model file\n","                  opset_version=13,            # the ONNX version to export the model to\n","                  input_names = ['input'],     # the model's input names\n","                  output_names = ['output'],   # the model's output names\n","                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n","                                'output' : {0 : 'batch_size'}})"]},{"cell_type":"markdown","id":"60824520","metadata":{"id":"60824520"},"source":["# Export to TensorRT\n","\n","TensorRT is a library that focuses specifically on running an already trained network quickly and efficiently on a GPU for high performance inference on NVIDIA GPUs. However, some pre-processing steps maybe required before converting the ONNX model to TensorRT inference engine."]},{"cell_type":"markdown","id":"f50d4f54","metadata":{"id":"f50d4f54"},"source":["## Using Polygraph\n","\n","Polygraphy is a toolkit designed to assist in running and debugging deep learning models. It can run inference among different model formats, convert models to other formats, compare performance of models, all through the comamnd-line."]},{"cell_type":"markdown","id":"913d48fa","metadata":{"id":"913d48fa"},"source":["The `surgeon sanitize` subtool can be used to fold constants in graphs and remove unused nodes. In cases where shapes are statically known, it can also simplify subgraphs involving shape operations. A simple example is shown below:\n","\n","Suppose you are computing, `output = input + ((a + b) + c)` where `a`, `b` and `c` are constants. By running the command given below, `polygraph` will collapse `a`, `b` and `c` into a single constant tensor, simplifying the equation to `output = input + d`.\n","\n","Polygraphy's surgeon tool provides a constant folding function, which is an important step for newer models before converting the ONNX model into TensorRT."]},{"cell_type":"code","execution_count":null,"id":"65a0ad7d","metadata":{"id":"65a0ad7d"},"outputs":[],"source":["## Use this for EfficientNetV2\n","#!polygraphy surgeon sanitize $ONNX_MODEL_PATH --fold-constant -o $ONNX_MODEL_PATH"]},{"cell_type":"markdown","id":"0e03ba2e","metadata":{"id":"0e03ba2e"},"source":["You can use the `run` subtool to compare the ONNX model between TensorRT and ONNX Runtime."]},{"cell_type":"code","execution_count":null,"id":"b0a9a2e4","metadata":{"id":"b0a9a2e4","outputId":"aaa09c40-2a2e-482a-f613-918fb56a738c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[W] 'colored' module is not installed, will not use colors when logging. To enable colors, please install the 'colored' module: python3 -m pip install colored\n","[I] trt-runner-N0-07/22/22-13:09:21     | Activating and starting inference\n","[07/22/2022-13:09:22] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n","[W]     Input tensor: input (dtype=DataType.FLOAT, shape=(-1, 3, 224, 224)) | No shapes provided; Will use shape: [1, 3, 224, 224] for min/opt/max in profile.\n","[W]     This will cause the tensor to have a static shape. If this is incorrect, please set the range of shapes for this input tensor.\n","[I]     Configuring with profiles: [Profile().add(input, min=[1, 3, 224, 224], opt=[1, 3, 224, 224], max=[1, 3, 224, 224])]\n","[I] Building engine with configuration:\n","    Workspace            | 16777216 bytes (16.00 MiB)\n","    Precision            | TF32: False, FP16: False, INT8: False, Strict Types: False\n","    Tactic Sources       | ['CUBLAS', 'CUBLAS_LT', 'CUDNN']\n","    Safety Restricted    | False\n","    Profiles             | 1 profile(s)\n","[I] Finished engine building in 15.063 seconds\n","[I] trt-runner-N0-07/22/22-13:09:21    \n","    ---- Inference Input(s) ----\n","    {input [dtype=float32, shape=(1, 3, 224, 224)]}\n","[I] trt-runner-N0-07/22/22-13:09:21    \n","    ---- Inference Output(s) ----\n","    {output [dtype=float32, shape=(1, 2)]}\n","[I] trt-runner-N0-07/22/22-13:09:21     | Completed 1 iteration(s) in 3.673 ms | Average inference time: 3.673 ms.\n","[I] onnxrt-runner-N0-07/22/22-13:09:21  | Activating and starting inference\n","[!] Module: 'onnxruntime' is required but could not be imported.\n","    You can try setting POLYGRAPHY_AUTOINSTALL_DEPS=1 in your environment variables to allow Polygraphy to automatically install missing modules.\n","    Note that this may cause existing modules to be overwritten - hence, it may be desirable to use a Python virtual environment or container. \n"]}],"source":["!polygraphy run $ONNX_MODEL_PATH --trt --onnxrt"]},{"cell_type":"markdown","id":"49ebf1fe","metadata":{"id":"49ebf1fe"},"source":["## Exporting to TensorRT inference engine\n","\n","Finally, the model is converted to TensorRT inference engine using `trtexec`, a command-line tool for working with TensorRT. The various flags used here are explained below:\n","\n","The `explicitBatch` flag signals to TensorRT that we will be using a fixed batch size at runtime. `minShapes` and `maxShapes`, like their name suggests, are the minimum and maximum shaped tensors that you want to pass for inferencing, while `optShapes` is the preferred shape"]},{"cell_type":"markdown","id":"ec0ea440","metadata":{"id":"ec0ea440"},"source":["### FP32 Conversion"]},{"cell_type":"code","execution_count":null,"id":"45ac6532","metadata":{"id":"45ac6532","outputId":"a8b0b1a0-8b53-40b3-b76f-87551430774d"},"outputs":[{"name":"stdout","output_type":"stream","text":["&&&& RUNNING TensorRT.trtexec [TensorRT v8205] # trtexec --onnx=./triton_model_repository/resnet50_onnx/1/model.onnx --explicitBatch --workspace=16382 --optShapes=input:8x3x224x224 --maxShapes=input:128x3x224x224 --minShapes=input:1x3x224x224 --saveEngine=./triton_model_repository/resnet50_trt_fp32/1/model.plan\n","[07/22/2022-13:09:46] [W] --explicitBatch flag has been deprecated and has no effect!\n","[07/22/2022-13:09:46] [W] Explicit batch dim is automatically enabled if input model is ONNX or if dynamic shapes are provided when the engine is built.\n","[07/22/2022-13:09:46] [I] === Model Options ===\n","[07/22/2022-13:09:46] [I] Format: ONNX\n","[07/22/2022-13:09:46] [I] Model: ./triton_model_repository/resnet50_onnx/1/model.onnx\n","[07/22/2022-13:09:46] [I] Output:\n","[07/22/2022-13:09:46] [I] === Build Options ===\n","[07/22/2022-13:09:46] [I] Max batch: explicit batch\n","[07/22/2022-13:09:46] [I] Workspace: 16382 MiB\n","[07/22/2022-13:09:46] [I] minTiming: 1\n","[07/22/2022-13:09:46] [I] avgTiming: 8\n","[07/22/2022-13:09:46] [I] Precision: FP32\n","[07/22/2022-13:09:46] [I] Calibration: \n","[07/22/2022-13:09:46] [I] Refit: Disabled\n","[07/22/2022-13:09:46] [I] Sparsity: Disabled\n","[07/22/2022-13:09:46] [I] Safe mode: Disabled\n","[07/22/2022-13:09:46] [I] DirectIO mode: Disabled\n","[07/22/2022-13:09:46] [I] Restricted mode: Disabled\n","[07/22/2022-13:09:46] [I] Save engine: ./triton_model_repository/resnet50_trt_fp32/1/model.plan\n","[07/22/2022-13:09:46] [I] Load engine: \n","[07/22/2022-13:09:46] [I] Profiling verbosity: 0\n","[07/22/2022-13:09:46] [I] Tactic sources: Using default tactic sources\n","[07/22/2022-13:09:46] [I] timingCacheMode: local\n","[07/22/2022-13:09:46] [I] timingCacheFile: \n","[07/22/2022-13:09:46] [I] Input(s)s format: fp32:CHW\n","[07/22/2022-13:09:46] [I] Output(s)s format: fp32:CHW\n","[07/22/2022-13:09:46] [I] Input build shape: input=1x3x224x224+8x3x224x224+128x3x224x224\n","[07/22/2022-13:09:46] [I] Input calibration shapes: model\n","[07/22/2022-13:09:46] [I] === System Options ===\n","[07/22/2022-13:09:46] [I] Device: 0\n","[07/22/2022-13:09:46] [I] DLACore: \n","[07/22/2022-13:09:46] [I] Plugins:\n","[07/22/2022-13:09:46] [I] === Inference Options ===\n","[07/22/2022-13:09:46] [I] Batch: Explicit\n","[07/22/2022-13:09:46] [I] Input inference shape: input=8x3x224x224\n","[07/22/2022-13:09:46] [I] Iterations: 10\n","[07/22/2022-13:09:46] [I] Duration: 3s (+ 200ms warm up)\n","[07/22/2022-13:09:46] [I] Sleep time: 0ms\n","[07/22/2022-13:09:46] [I] Idle time: 0ms\n","[07/22/2022-13:09:46] [I] Streams: 1\n","[07/22/2022-13:09:46] [I] ExposeDMA: Disabled\n","[07/22/2022-13:09:46] [I] Data transfers: Enabled\n","[07/22/2022-13:09:46] [I] Spin-wait: Disabled\n","[07/22/2022-13:09:46] [I] Multithreading: Disabled\n","[07/22/2022-13:09:46] [I] CUDA Graph: Disabled\n","[07/22/2022-13:09:46] [I] Separate profiling: Disabled\n","[07/22/2022-13:09:46] [I] Time Deserialize: Disabled\n","[07/22/2022-13:09:46] [I] Time Refit: Disabled\n","[07/22/2022-13:09:46] [I] Skip inference: Disabled\n","[07/22/2022-13:09:46] [I] Inputs:\n","[07/22/2022-13:09:46] [I] === Reporting Options ===\n","[07/22/2022-13:09:46] [I] Verbose: Disabled\n","[07/22/2022-13:09:46] [I] Averages: 10 inferences\n","[07/22/2022-13:09:46] [I] Percentile: 99\n","[07/22/2022-13:09:46] [I] Dump refittable layers:Disabled\n","[07/22/2022-13:09:46] [I] Dump output: Disabled\n","[07/22/2022-13:09:46] [I] Profile: Disabled\n","[07/22/2022-13:09:46] [I] Export timing to JSON file: \n","[07/22/2022-13:09:46] [I] Export output to JSON file: \n","[07/22/2022-13:09:46] [I] Export profile to JSON file: \n","[07/22/2022-13:09:46] [I] \n","[07/22/2022-13:09:46] [I] === Device Information ===\n","[07/22/2022-13:09:46] [I] Selected Device: NVIDIA A100-SXM4-80GB\n","[07/22/2022-13:09:46] [I] Compute Capability: 8.0\n","[07/22/2022-13:09:46] [I] SMs: 108\n","[07/22/2022-13:09:46] [I] Compute Clock Rate: 1.41 GHz\n","[07/22/2022-13:09:46] [I] Device Global Memory: 81251 MiB\n","[07/22/2022-13:09:46] [I] Shared Memory per SM: 164 KiB\n","[07/22/2022-13:09:46] [I] Memory Bus Width: 5120 bits (ECC enabled)\n","[07/22/2022-13:09:46] [I] Memory Clock Rate: 1.593 GHz\n","[07/22/2022-13:09:46] [I] \n","[07/22/2022-13:09:46] [I] TensorRT version: 8.2.5\n","[07/22/2022-13:09:47] [I] [TRT] [MemUsageChange] Init CUDA: CPU +440, GPU +0, now: CPU 452, GPU 8810 (MiB)\n","[07/22/2022-13:09:47] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 452 MiB, GPU 8810 MiB\n","[07/22/2022-13:09:47] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 669 MiB, GPU 8882 MiB\n","[07/22/2022-13:09:47] [I] Start parsing network model\n","[07/22/2022-13:09:47] [I] [TRT] ----------------------------------------------------------------\n","[07/22/2022-13:09:47] [I] [TRT] Input filename:   ./triton_model_repository/resnet50_onnx/1/model.onnx\n","[07/22/2022-13:09:47] [I] [TRT] ONNX IR version:  0.0.7\n","[07/22/2022-13:09:47] [I] [TRT] Opset version:    13\n","[07/22/2022-13:09:47] [I] [TRT] Producer name:    pytorch\n","[07/22/2022-13:09:47] [I] [TRT] Producer version: 1.13.0\n","[07/22/2022-13:09:47] [I] [TRT] Domain:           \n","[07/22/2022-13:09:47] [I] [TRT] Model version:    0\n","[07/22/2022-13:09:47] [I] [TRT] Doc string:       \n","[07/22/2022-13:09:47] [I] [TRT] ----------------------------------------------------------------\n","[07/22/2022-13:09:47] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n","[07/22/2022-13:09:47] [I] Finish parsing network model\n","[07/22/2022-13:09:49] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +839, GPU +362, now: CPU 1617, GPU 9252 (MiB)\n","[07/22/2022-13:09:49] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +128, GPU +58, now: CPU 1745, GPU 9310 (MiB)\n","[07/22/2022-13:09:49] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n","[07/22/2022-13:10:31] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n","[07/22/2022-13:10:31] [I] [TRT] Total Host Persistent Memory: 128880\n","[07/22/2022-13:10:31] [I] [TRT] Total Device Persistent Memory: 94215168\n","[07/22/2022-13:10:31] [I] [TRT] Total Scratch Memory: 4194304\n","[07/22/2022-13:10:31] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 9 MiB, GPU 3023 MiB\n","[07/22/2022-13:10:31] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 1.89663ms to assign 4 blocks to 65 nodes requiring 1027604481 bytes.\n","[07/22/2022-13:10:31] [I] [TRT] Total Activation Memory: 1027604481\n","[07/22/2022-13:10:31] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2598, GPU 9804 (MiB)\n","[07/22/2022-13:10:31] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2598, GPU 9814 (MiB)\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +94, now: CPU 0, GPU 94 (MiB)\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2691, GPU 9686 (MiB)\n","[07/22/2022-13:10:32] [I] [TRT] Loaded engine size: 94 MiB\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2692, GPU 9790 (MiB)\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2692, GPU 9798 (MiB)\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +93, now: CPU 0, GPU 93 (MiB)\n","[07/22/2022-13:10:32] [I] Engine built in 46.0599 sec.\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2288, GPU 9740 (MiB)\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2288, GPU 9748 (MiB)\n","[07/22/2022-13:10:32] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1070, now: CPU 0, GPU 1163 (MiB)\n","[07/22/2022-13:10:32] [I] Using random values for input input\n","[07/22/2022-13:10:32] [I] Created input binding for input with dimensions 8x3x224x224\n","[07/22/2022-13:10:32] [I] Using random values for output output\n","[07/22/2022-13:10:32] [I] Created output binding for output with dimensions 8x2\n","[07/22/2022-13:10:32] [I] Starting inference\n","[07/22/2022-13:10:35] [I] Warmup completed 118 queries over 200 ms\n","[07/22/2022-13:10:35] [I] Timing trace has 1605 queries over 3.00402 s\n","[07/22/2022-13:10:35] [I] \n","[07/22/2022-13:10:35] [I] === Trace details ===\n","[07/22/2022-13:10:35] [I] Trace averages of 10 runs:\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69201 ms - Host latency: 2.07833 ms (end to end 3.33278 ms, enqueue 0.282784 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71172 ms - Host latency: 1.98607 ms (end to end 3.36483 ms, enqueue 0.266051 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67722 ms - Host latency: 1.92011 ms (end to end 3.29542 ms, enqueue 0.246164 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67807 ms - Host latency: 1.93132 ms (end to end 3.15194 ms, enqueue 0.27596 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.716 ms - Host latency: 1.96202 ms (end to end 2.70313 ms, enqueue 0.282339 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67685 ms - Host latency: 1.90913 ms (end to end 3.13389 ms, enqueue 0.273724 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67785 ms - Host latency: 1.90975 ms (end to end 2.86802 ms, enqueue 0.243494 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67931 ms - Host latency: 1.91274 ms (end to end 2.77863 ms, enqueue 0.239917 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.68731 ms - Host latency: 1.96049 ms (end to end 3.01227 ms, enqueue 0.251505 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69627 ms - Host latency: 1.92763 ms (end to end 3.23393 ms, enqueue 0.243253 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67811 ms - Host latency: 1.93779 ms (end to end 3.30567 ms, enqueue 0.275513 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67886 ms - Host latency: 1.94292 ms (end to end 2.98243 ms, enqueue 0.245544 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67802 ms - Host latency: 1.94244 ms (end to end 3.29407 ms, enqueue 0.253699 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67773 ms - Host latency: 1.94063 ms (end to end 3.29254 ms, enqueue 0.257281 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.72824 ms - Host latency: 2.08773 ms (end to end 3.39248 ms, enqueue 0.267538 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67637 ms - Host latency: 1.93701 ms (end to end 3.04486 ms, enqueue 0.246497 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67651 ms - Host latency: 1.90585 ms (end to end 3.14255 ms, enqueue 0.267511 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67579 ms - Host latency: 1.91224 ms (end to end 3.16386 ms, enqueue 0.243207 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67646 ms - Host latency: 1.90251 ms (end to end 3.12211 ms, enqueue 0.253699 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.75388 ms - Host latency: 2.09371 ms (end to end 3.44168 ms, enqueue 0.277454 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67879 ms - Host latency: 1.94678 ms (end to end 3.29916 ms, enqueue 0.245746 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67711 ms - Host latency: 1.90826 ms (end to end 2.86999 ms, enqueue 0.274646 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67736 ms - Host latency: 1.90707 ms (end to end 3.1425 ms, enqueue 0.250653 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67664 ms - Host latency: 1.89119 ms (end to end 2.85002 ms, enqueue 0.267377 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69579 ms - Host latency: 1.92225 ms (end to end 2.93773 ms, enqueue 0.24447 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.7401 ms - Host latency: 2.06722 ms (end to end 3.4336 ms, enqueue 0.273505 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6788 ms - Host latency: 1.92606 ms (end to end 3.29862 ms, enqueue 0.243665 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67777 ms - Host latency: 1.89086 ms (end to end 3.29446 ms, enqueue 0.238202 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6775 ms - Host latency: 1.89262 ms (end to end 3.29741 ms, enqueue 0.249347 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67462 ms - Host latency: 1.88842 ms (end to end 3.29178 ms, enqueue 0.257501 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67723 ms - Host latency: 1.89455 ms (end to end 3.29232 ms, enqueue 0.239868 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.70743 ms - Host latency: 1.95883 ms (end to end 3.33309 ms, enqueue 0.251324 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67798 ms - Host latency: 1.8966 ms (end to end 3.29337 ms, enqueue 0.259979 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67676 ms - Host latency: 1.89517 ms (end to end 3.29196 ms, enqueue 0.241461 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67707 ms - Host latency: 1.89633 ms (end to end 3.29478 ms, enqueue 0.255841 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67816 ms - Host latency: 1.89818 ms (end to end 3.29532 ms, enqueue 0.259143 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.68058 ms - Host latency: 1.90711 ms (end to end 3.29977 ms, enqueue 0.266663 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71842 ms - Host latency: 2.00308 ms (end to end 3.33839 ms, enqueue 0.273254 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67628 ms - Host latency: 1.89021 ms (end to end 3.2941 ms, enqueue 0.245862 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67748 ms - Host latency: 1.89036 ms (end to end 3.29623 ms, enqueue 0.272827 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67585 ms - Host latency: 1.88702 ms (end to end 3.29486 ms, enqueue 0.239709 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67652 ms - Host latency: 1.88924 ms (end to end 3.29412 ms, enqueue 0.241382 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67875 ms - Host latency: 1.90114 ms (end to end 3.29431 ms, enqueue 0.257111 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.72098 ms - Host latency: 1.97953 ms (end to end 3.38056 ms, enqueue 0.253992 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67699 ms - Host latency: 1.88673 ms (end to end 3.29562 ms, enqueue 0.239722 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67582 ms - Host latency: 1.88661 ms (end to end 3.29469 ms, enqueue 0.241663 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67673 ms - Host latency: 1.88912 ms (end to end 3.29098 ms, enqueue 0.252771 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67729 ms - Host latency: 1.88668 ms (end to end 3.2968 ms, enqueue 0.240625 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67786 ms - Host latency: 1.90625 ms (end to end 3.29642 ms, enqueue 0.248718 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69647 ms - Host latency: 1.92382 ms (end to end 3.33281 ms, enqueue 0.250562 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67772 ms - Host latency: 1.91205 ms (end to end 3.29463 ms, enqueue 0.274817 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71221 ms - Host latency: 1.94629 ms (end to end 3.36218 ms, enqueue 0.248193 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67682 ms - Host latency: 1.91295 ms (end to end 3.29419 ms, enqueue 0.263037 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67729 ms - Host latency: 1.91364 ms (end to end 3.29559 ms, enqueue 0.246936 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71541 ms - Host latency: 1.99663 ms (end to end 3.36479 ms, enqueue 0.247876 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67705 ms - Host latency: 1.89784 ms (end to end 3.29319 ms, enqueue 0.245105 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67748 ms - Host latency: 1.88772 ms (end to end 3.29644 ms, enqueue 0.256702 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6777 ms - Host latency: 1.88712 ms (end to end 3.24995 ms, enqueue 0.249536 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67711 ms - Host latency: 1.88602 ms (end to end 3.2933 ms, enqueue 0.255176 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67656 ms - Host latency: 1.88541 ms (end to end 3.29423 ms, enqueue 0.257922 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71724 ms - Host latency: 2.00479 ms (end to end 3.37643 ms, enqueue 0.273108 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67958 ms - Host latency: 1.90657 ms (end to end 2.95769 ms, enqueue 0.243298 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67842 ms - Host latency: 1.88706 ms (end to end 2.86213 ms, enqueue 0.242529 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67749 ms - Host latency: 1.88591 ms (end to end 3.29576 ms, enqueue 0.257886 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.63334 ms - Host latency: 2.86064 ms (end to end 3.62329 ms, enqueue 1.46814 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.9802 ms - Host latency: 2.30221 ms (end to end 3.02761 ms, enqueue 0.636438 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67751 ms - Host latency: 1.93252 ms (end to end 2.74795 ms, enqueue 0.278613 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6787 ms - Host latency: 1.91093 ms (end to end 2.93069 ms, enqueue 0.262451 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69722 ms - Host latency: 1.92997 ms (end to end 3.23013 ms, enqueue 0.262695 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69025 ms - Host latency: 1.98693 ms (end to end 3.31027 ms, enqueue 0.278284 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67649 ms - Host latency: 1.9031 ms (end to end 3.2885 ms, enqueue 0.256299 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67753 ms - Host latency: 1.90609 ms (end to end 3.29213 ms, enqueue 0.267566 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67756 ms - Host latency: 1.9026 ms (end to end 3.29106 ms, enqueue 0.248291 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67679 ms - Host latency: 1.88821 ms (end to end 3.28467 ms, enqueue 0.245325 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.22272 ms - Host latency: 2.64734 ms (end to end 3.68486 ms, enqueue 0.795532 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.68033 ms - Host latency: 1.92499 ms (end to end 3.28601 ms, enqueue 0.276465 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67612 ms - Host latency: 1.88236 ms (end to end 2.86584 ms, enqueue 0.24646 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.678 ms - Host latency: 1.88439 ms (end to end 3.1963 ms, enqueue 0.24613 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67739 ms - Host latency: 1.90571 ms (end to end 2.80306 ms, enqueue 0.283533 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.84435 ms - Host latency: 2.10815 ms (end to end 3.29966 ms, enqueue 0.457996 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67738 ms - Host latency: 1.89077 ms (end to end 3.28723 ms, enqueue 0.257568 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67618 ms - Host latency: 1.88406 ms (end to end 3.28843 ms, enqueue 0.265613 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.26399 ms - Host latency: 2.66855 ms (end to end 3.66837 ms, enqueue 0.973022 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67723 ms - Host latency: 1.88314 ms (end to end 3.29012 ms, enqueue 0.283679 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6792 ms - Host latency: 1.91193 ms (end to end 3.29288 ms, enqueue 0.261328 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.29585 ms - Host latency: 2.57749 ms (end to end 3.54867 ms, enqueue 0.988916 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.30851 ms - Host latency: 2.53766 ms (end to end 3.57125 ms, enqueue 0.796277 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67671 ms - Host latency: 1.88392 ms (end to end 3.29008 ms, enqueue 0.268591 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.30769 ms - Host latency: 2.53196 ms (end to end 3.58488 ms, enqueue 1.15601 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.73665 ms - Host latency: 1.99598 ms (end to end 3.26155 ms, enqueue 0.288257 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.1694 ms - Host latency: 2.40071 ms (end to end 3.67891 ms, enqueue 1.05032 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.83816 ms - Host latency: 2.0548 ms (end to end 3.43359 ms, enqueue 0.447241 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67615 ms - Host latency: 1.88506 ms (end to end 3.28921 ms, enqueue 0.260852 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67659 ms - Host latency: 2.06573 ms (end to end 3.33164 ms, enqueue 0.260718 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.05895 ms - Host latency: 2.31422 ms (end to end 3.41394 ms, enqueue 0.793286 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6767 ms - Host latency: 1.88522 ms (end to end 3.30518 ms, enqueue 0.258423 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67643 ms - Host latency: 1.88177 ms (end to end 3.28823 ms, enqueue 0.255383 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67703 ms - Host latency: 1.88489 ms (end to end 3.29163 ms, enqueue 0.263623 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.46272 ms - Host latency: 2.68918 ms (end to end 4.17939 ms, enqueue 1.32119 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67815 ms - Host latency: 1.92034 ms (end to end 3.27813 ms, enqueue 0.261157 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71143 ms - Host latency: 1.94065 ms (end to end 3.35645 ms, enqueue 0.285498 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67659 ms - Host latency: 1.88855 ms (end to end 3.2887 ms, enqueue 0.26543 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.82246 ms - Host latency: 3.05933 ms (end to end 4.18142 ms, enqueue 1.97517 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67708 ms - Host latency: 1.88845 ms (end to end 3.28557 ms, enqueue 0.278125 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71338 ms - Host latency: 1.94536 ms (end to end 3.35325 ms, enqueue 0.277441 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.05281 ms - Host latency: 2.28152 ms (end to end 3.48828 ms, enqueue 0.975195 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.9552 ms - Host latency: 2.17607 ms (end to end 3.36111 ms, enqueue 0.610522 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67693 ms - Host latency: 1.88242 ms (end to end 3.28843 ms, enqueue 0.255566 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.676 ms - Host latency: 1.87969 ms (end to end 3.28687 ms, enqueue 0.252295 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.87339 ms - Host latency: 2.09722 ms (end to end 3.10718 ms, enqueue 0.834399 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 2.05945 ms - Host latency: 2.34067 ms (end to end 3.12014 ms, enqueue 0.658691 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67703 ms - Host latency: 1.88223 ms (end to end 2.87651 ms, enqueue 0.257715 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.99653 ms - Host latency: 2.22061 ms (end to end 3.11213 ms, enqueue 0.634204 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67705 ms - Host latency: 1.88091 ms (end to end 2.9365 ms, enqueue 0.276953 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67832 ms - Host latency: 1.88894 ms (end to end 3.16687 ms, enqueue 0.268408 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67854 ms - Host latency: 1.89675 ms (end to end 3.19639 ms, enqueue 0.26792 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69583 ms - Host latency: 1.90315 ms (end to end 3.26353 ms, enqueue 0.254321 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71487 ms - Host latency: 1.96077 ms (end to end 2.95764 ms, enqueue 0.267188 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.69761 ms - Host latency: 1.90518 ms (end to end 3.06064 ms, enqueue 0.259351 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67729 ms - Host latency: 1.89536 ms (end to end 2.98013 ms, enqueue 0.278833 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71382 ms - Host latency: 1.95459 ms (end to end 3.35603 ms, enqueue 0.30332 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67725 ms - Host latency: 1.88105 ms (end to end 3.12871 ms, enqueue 0.263428 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67632 ms - Host latency: 1.87866 ms (end to end 2.95388 ms, enqueue 0.254102 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67544 ms - Host latency: 1.88137 ms (end to end 3.14941 ms, enqueue 0.268555 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67708 ms - Host latency: 1.8877 ms (end to end 3.1197 ms, enqueue 0.241626 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.75166 ms - Host latency: 2.02068 ms (end to end 3.43071 ms, enqueue 0.282397 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67791 ms - Host latency: 1.89412 ms (end to end 3.28833 ms, enqueue 0.244092 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67632 ms - Host latency: 1.8801 ms (end to end 3.08806 ms, enqueue 0.265308 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67651 ms - Host latency: 1.87952 ms (end to end 3.03921 ms, enqueue 0.240405 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67615 ms - Host latency: 1.87986 ms (end to end 3.15076 ms, enqueue 0.25398 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67712 ms - Host latency: 1.89458 ms (end to end 2.83428 ms, enqueue 0.263403 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.72183 ms - Host latency: 1.93328 ms (end to end 3.11704 ms, enqueue 0.250977 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67703 ms - Host latency: 1.88394 ms (end to end 3.16956 ms, enqueue 0.271362 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67686 ms - Host latency: 1.87964 ms (end to end 3.28799 ms, enqueue 0.24187 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67749 ms - Host latency: 1.88035 ms (end to end 3.29133 ms, enqueue 0.248682 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6769 ms - Host latency: 1.87996 ms (end to end 3.28931 ms, enqueue 0.242065 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67693 ms - Host latency: 1.88032 ms (end to end 3.29072 ms, enqueue 0.242041 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.70986 ms - Host latency: 1.94414 ms (end to end 3.35339 ms, enqueue 0.295801 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67717 ms - Host latency: 1.88105 ms (end to end 3.29248 ms, enqueue 0.2552 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67737 ms - Host latency: 1.88091 ms (end to end 3.29336 ms, enqueue 0.26001 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67791 ms - Host latency: 1.88125 ms (end to end 3.29126 ms, enqueue 0.259863 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67659 ms - Host latency: 1.87966 ms (end to end 3.29067 ms, enqueue 0.273486 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67764 ms - Host latency: 1.88069 ms (end to end 3.29065 ms, enqueue 0.244116 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.7311 ms - Host latency: 1.96785 ms (end to end 3.39219 ms, enqueue 0.282104 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67776 ms - Host latency: 1.88247 ms (end to end 3.27634 ms, enqueue 0.264893 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67688 ms - Host latency: 1.88132 ms (end to end 3.28896 ms, enqueue 0.243579 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67656 ms - Host latency: 1.88096 ms (end to end 3.29216 ms, enqueue 0.240967 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67676 ms - Host latency: 1.87998 ms (end to end 3.29216 ms, enqueue 0.248047 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67754 ms - Host latency: 1.8845 ms (end to end 3.29307 ms, enqueue 0.244751 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71296 ms - Host latency: 1.92351 ms (end to end 3.36179 ms, enqueue 0.254492 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.6771 ms - Host latency: 1.88162 ms (end to end 3.29006 ms, enqueue 0.243774 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67661 ms - Host latency: 1.88069 ms (end to end 3.29019 ms, enqueue 0.247705 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67729 ms - Host latency: 1.88176 ms (end to end 3.29255 ms, enqueue 0.243677 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67715 ms - Host latency: 1.88093 ms (end to end 3.28967 ms, enqueue 0.243115 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.71182 ms - Host latency: 1.92107 ms (end to end 3.35168 ms, enqueue 0.260156 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67695 ms - Host latency: 1.88494 ms (end to end 3.28228 ms, enqueue 0.263257 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67607 ms - Host latency: 1.89255 ms (end to end 3.1429 ms, enqueue 0.243677 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67781 ms - Host latency: 1.88147 ms (end to end 3.29409 ms, enqueue 0.242896 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67773 ms - Host latency: 1.88142 ms (end to end 3.29146 ms, enqueue 0.24729 ms)\n","[07/22/2022-13:10:35] [I] Average on 10 runs - GPU latency: 1.67747 ms - Host latency: 1.88125 ms (end to end 3.28989 ms, enqueue 0.252271 ms)\n","[07/22/2022-13:10:35] [I] \n","[07/22/2022-13:10:35] [I] === Performance summary ===\n","[07/22/2022-13:10:35] [I] Throughput: 534.284 qps\n","[07/22/2022-13:10:35] [I] Latency: min = 1.87109 ms, max = 8.07349 ms, mean = 1.97197 ms, median = 1.88953 ms, percentile(99%) = 5.00171 ms\n","[07/22/2022-13:10:35] [I] End-to-End Host Latency: min = 1.88867 ms, max = 9.48804 ms, mean = 3.25408 ms, median = 3.2915 ms, percentile(99%) = 5.0791 ms\n","[07/22/2022-13:10:35] [I] Enqueue Time: min = 0.232666 ms, max = 9.0415 ms, mean = 0.332341 ms, median = 0.246826 ms, percentile(99%) = 3.77856 ms\n","[07/22/2022-13:10:35] [I] H2D Latency: min = 0.193115 ms, max = 2.01904 ms, mean = 0.222879 ms, median = 0.202393 ms, percentile(99%) = 0.442383 ms\n","[07/22/2022-13:10:35] [I] GPU Compute Time: min = 1.66919 ms, max = 7.86572 ms, mean = 1.74019 ms, median = 1.67743 ms, percentile(99%) = 4.54578 ms\n","[07/22/2022-13:10:35] [I] D2H Latency: min = 0.00634766 ms, max = 0.019043 ms, mean = 0.00889456 ms, median = 0.0090332 ms, percentile(99%) = 0.0109863 ms\n","[07/22/2022-13:10:35] [I] Total Host Walltime: 3.00402 s\n","[07/22/2022-13:10:35] [I] Total GPU Compute Time: 2.79301 s\n","[07/22/2022-13:10:35] [I] Explanations of the performance metrics are printed in the verbose logs.\n","[07/22/2022-13:10:35] [I] \n","&&&& PASSED TensorRT.trtexec [TensorRT v8205] # trtexec --onnx=./triton_model_repository/resnet50_onnx/1/model.onnx --explicitBatch --workspace=16382 --optShapes=input:8x3x224x224 --maxShapes=input:128x3x224x224 --minShapes=input:1x3x224x224 --saveEngine=./triton_model_repository/resnet50_trt_fp32/1/model.plan\n"]}],"source":["!trtexec \\\n","  --onnx=$ONNX_MODEL_PATH \\\n","  --explicitBatch \\\n","  --workspace=16382 \\\n","  --optShapes=input:8x3x224x224 \\\n","  --maxShapes=input:128x3x224x224 \\\n","  --minShapes=input:1x3x224x224 \\\n","  --saveEngine=$TRT_MODEL_PATH"]},{"cell_type":"markdown","id":"dfeb6dcd","metadata":{"id":"dfeb6dcd"},"source":["**if CHANNEL_LAST**\n","\n","\n","`!trtexec \\\n","  --onnx=$ONNX_MODEL_PATH \\\n","  --explicitBatch \\\n","  --workspace=16382 \\\n","  --optShapes=input:8x224x224x3 \\\n","  --maxShapes=input:128x224x224x3 \\\n","  --minShapes=input:1x224x224x3 \\\n","  --saveEngine=$TRT_MODEL_PATH'`"]},{"cell_type":"markdown","id":"a06995da","metadata":{"id":"a06995da"},"source":["### FP16 Conversion\n","\n","As lower precision tends to run faster, we can convert the ONNX model to FP16 precision by simply passing the flag `--fp16`."]},{"cell_type":"code","execution_count":null,"id":"3e4acfdb","metadata":{"id":"3e4acfdb","outputId":"1bc28e99-760e-4f42-efe6-0e68a06778e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["&&&& RUNNING TensorRT.trtexec [TensorRT v8205] # trtexec --onnx=./triton_model_repository/resnet50_onnx/1/model.onnx --explicitBatch --workspace=16382 --optShapes=input:8x3x224x224 --maxShapes=input:128x3x224x224 --minShapes=input:1x3x224x224 --saveEngine=./triton_model_repository/resnet50_trt_fp16/1/model.plan --fp16\n","[07/22/2022-13:10:36] [W] --explicitBatch flag has been deprecated and has no effect!\n","[07/22/2022-13:10:36] [W] Explicit batch dim is automatically enabled if input model is ONNX or if dynamic shapes are provided when the engine is built.\n","[07/22/2022-13:10:36] [I] === Model Options ===\n","[07/22/2022-13:10:36] [I] Format: ONNX\n","[07/22/2022-13:10:36] [I] Model: ./triton_model_repository/resnet50_onnx/1/model.onnx\n","[07/22/2022-13:10:36] [I] Output:\n","[07/22/2022-13:10:36] [I] === Build Options ===\n","[07/22/2022-13:10:36] [I] Max batch: explicit batch\n","[07/22/2022-13:10:36] [I] Workspace: 16382 MiB\n","[07/22/2022-13:10:36] [I] minTiming: 1\n","[07/22/2022-13:10:36] [I] avgTiming: 8\n","[07/22/2022-13:10:36] [I] Precision: FP32+FP16\n","[07/22/2022-13:10:36] [I] Calibration: \n","[07/22/2022-13:10:36] [I] Refit: Disabled\n","[07/22/2022-13:10:36] [I] Sparsity: Disabled\n","[07/22/2022-13:10:36] [I] Safe mode: Disabled\n","[07/22/2022-13:10:36] [I] DirectIO mode: Disabled\n","[07/22/2022-13:10:36] [I] Restricted mode: Disabled\n","[07/22/2022-13:10:36] [I] Save engine: ./triton_model_repository/resnet50_trt_fp16/1/model.plan\n","[07/22/2022-13:10:36] [I] Load engine: \n","[07/22/2022-13:10:36] [I] Profiling verbosity: 0\n","[07/22/2022-13:10:36] [I] Tactic sources: Using default tactic sources\n","[07/22/2022-13:10:36] [I] timingCacheMode: local\n","[07/22/2022-13:10:36] [I] timingCacheFile: \n","[07/22/2022-13:10:36] [I] Input(s)s format: fp32:CHW\n","[07/22/2022-13:10:36] [I] Output(s)s format: fp32:CHW\n","[07/22/2022-13:10:36] [I] Input build shape: input=1x3x224x224+8x3x224x224+128x3x224x224\n","[07/22/2022-13:10:36] [I] Input calibration shapes: model\n","[07/22/2022-13:10:36] [I] === System Options ===\n","[07/22/2022-13:10:36] [I] Device: 0\n","[07/22/2022-13:10:36] [I] DLACore: \n","[07/22/2022-13:10:36] [I] Plugins:\n","[07/22/2022-13:10:36] [I] === Inference Options ===\n","[07/22/2022-13:10:36] [I] Batch: Explicit\n","[07/22/2022-13:10:36] [I] Input inference shape: input=8x3x224x224\n","[07/22/2022-13:10:36] [I] Iterations: 10\n","[07/22/2022-13:10:36] [I] Duration: 3s (+ 200ms warm up)\n","[07/22/2022-13:10:36] [I] Sleep time: 0ms\n","[07/22/2022-13:10:36] [I] Idle time: 0ms\n","[07/22/2022-13:10:36] [I] Streams: 1\n","[07/22/2022-13:10:36] [I] ExposeDMA: Disabled\n","[07/22/2022-13:10:36] [I] Data transfers: Enabled\n","[07/22/2022-13:10:36] [I] Spin-wait: Disabled\n","[07/22/2022-13:10:36] [I] Multithreading: Disabled\n","[07/22/2022-13:10:36] [I] CUDA Graph: Disabled\n","[07/22/2022-13:10:36] [I] Separate profiling: Disabled\n","[07/22/2022-13:10:36] [I] Time Deserialize: Disabled\n","[07/22/2022-13:10:36] [I] Time Refit: Disabled\n","[07/22/2022-13:10:36] [I] Skip inference: Disabled\n","[07/22/2022-13:10:36] [I] Inputs:\n","[07/22/2022-13:10:36] [I] === Reporting Options ===\n","[07/22/2022-13:10:36] [I] Verbose: Disabled\n","[07/22/2022-13:10:36] [I] Averages: 10 inferences\n","[07/22/2022-13:10:36] [I] Percentile: 99\n","[07/22/2022-13:10:36] [I] Dump refittable layers:Disabled\n","[07/22/2022-13:10:36] [I] Dump output: Disabled\n","[07/22/2022-13:10:36] [I] Profile: Disabled\n","[07/22/2022-13:10:36] [I] Export timing to JSON file: \n","[07/22/2022-13:10:36] [I] Export output to JSON file: \n","[07/22/2022-13:10:36] [I] Export profile to JSON file: \n","[07/22/2022-13:10:36] [I] \n","[07/22/2022-13:10:37] [I] === Device Information ===\n","[07/22/2022-13:10:37] [I] Selected Device: NVIDIA A100-SXM4-80GB\n","[07/22/2022-13:10:37] [I] Compute Capability: 8.0\n","[07/22/2022-13:10:37] [I] SMs: 108\n","[07/22/2022-13:10:37] [I] Compute Clock Rate: 1.41 GHz\n","[07/22/2022-13:10:37] [I] Device Global Memory: 81251 MiB\n","[07/22/2022-13:10:37] [I] Shared Memory per SM: 164 KiB\n","[07/22/2022-13:10:37] [I] Memory Bus Width: 5120 bits (ECC enabled)\n","[07/22/2022-13:10:37] [I] Memory Clock Rate: 1.593 GHz\n","[07/22/2022-13:10:37] [I] \n","[07/22/2022-13:10:37] [I] TensorRT version: 8.2.5\n","[07/22/2022-13:10:37] [I] [TRT] [MemUsageChange] Init CUDA: CPU +440, GPU +0, now: CPU 452, GPU 8810 (MiB)\n","[07/22/2022-13:10:38] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 452 MiB, GPU 8810 MiB\n","[07/22/2022-13:10:38] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 669 MiB, GPU 8882 MiB\n","[07/22/2022-13:10:38] [I] Start parsing network model\n","[07/22/2022-13:10:38] [I] [TRT] ----------------------------------------------------------------\n","[07/22/2022-13:10:38] [I] [TRT] Input filename:   ./triton_model_repository/resnet50_onnx/1/model.onnx\n","[07/22/2022-13:10:38] [I] [TRT] ONNX IR version:  0.0.7\n","[07/22/2022-13:10:38] [I] [TRT] Opset version:    13\n","[07/22/2022-13:10:38] [I] [TRT] Producer name:    pytorch\n","[07/22/2022-13:10:38] [I] [TRT] Producer version: 1.13.0\n","[07/22/2022-13:10:38] [I] [TRT] Domain:           \n","[07/22/2022-13:10:38] [I] [TRT] Model version:    0\n","[07/22/2022-13:10:38] [I] [TRT] Doc string:       \n","[07/22/2022-13:10:38] [I] [TRT] ----------------------------------------------------------------\n","[07/22/2022-13:10:38] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n","[07/22/2022-13:10:38] [I] Finish parsing network model\n","[07/22/2022-13:10:40] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +839, GPU +362, now: CPU 1617, GPU 9252 (MiB)\n","[07/22/2022-13:10:40] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +128, GPU +58, now: CPU 1745, GPU 9310 (MiB)\n","[07/22/2022-13:10:40] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n","[07/22/2022-13:12:30] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n","[07/22/2022-13:12:31] [I] [TRT] Total Host Persistent Memory: 115248\n","[07/22/2022-13:12:31] [I] [TRT] Total Device Persistent Memory: 47172096\n","[07/22/2022-13:12:31] [I] [TRT] Total Scratch Memory: 4194304\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 47 MiB, GPU 3023 MiB\n","[07/22/2022-13:12:31] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 1.85684ms to assign 4 blocks to 64 nodes requiring 513802241 bytes.\n","[07/22/2022-13:12:31] [I] [TRT] Total Activation Memory: 513802241\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2643, GPU 9758 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2644, GPU 9768 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +45, GPU +47, now: CPU 45, GPU 47 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2645, GPU 9686 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] Loaded engine size: 47 MiB\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2646, GPU 9744 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2646, GPU 9752 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +46, now: CPU 0, GPU 46 (MiB)\n","[07/22/2022-13:12:31] [I] Engine built in 114.774 sec.\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2288, GPU 9694 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2288, GPU 9702 (MiB)\n","[07/22/2022-13:12:31] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +535, now: CPU 0, GPU 581 (MiB)\n","[07/22/2022-13:12:31] [I] Using random values for input input\n","[07/22/2022-13:12:31] [I] Created input binding for input with dimensions 8x3x224x224\n","[07/22/2022-13:12:31] [I] Using random values for output output\n","[07/22/2022-13:12:31] [I] Created output binding for output with dimensions 8x2\n","[07/22/2022-13:12:31] [I] Starting inference\n","[07/22/2022-13:12:35] [I] Warmup completed 200 queries over 200 ms\n","[07/22/2022-13:12:35] [I] Timing trace has 2812 queries over 3.00372 s\n","[07/22/2022-13:12:35] [I] \n","[07/22/2022-13:12:35] [I] === Trace details ===\n","[07/22/2022-13:12:35] [I] Trace averages of 10 runs:\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976959 ms - Host latency: 1.21141 ms (end to end 1.89362 ms, enqueue 0.235814 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977179 ms - Host latency: 1.21572 ms (end to end 1.8922 ms, enqueue 0.236986 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976401 ms - Host latency: 1.21372 ms (end to end 1.89219 ms, enqueue 0.235519 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977966 ms - Host latency: 1.21138 ms (end to end 1.89309 ms, enqueue 0.235075 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978229 ms - Host latency: 1.21246 ms (end to end 1.89605 ms, enqueue 0.235902 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976759 ms - Host latency: 1.21418 ms (end to end 1.88754 ms, enqueue 0.247945 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978143 ms - Host latency: 1.22592 ms (end to end 1.88169 ms, enqueue 0.31597 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979227 ms - Host latency: 1.22532 ms (end to end 1.88922 ms, enqueue 0.243298 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.00742 ms - Host latency: 1.27817 ms (end to end 1.93292 ms, enqueue 0.256308 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977097 ms - Host latency: 1.21799 ms (end to end 1.89073 ms, enqueue 0.233026 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977094 ms - Host latency: 1.21422 ms (end to end 1.89647 ms, enqueue 0.231775 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976132 ms - Host latency: 1.21149 ms (end to end 1.89206 ms, enqueue 0.230908 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97666 ms - Host latency: 1.21139 ms (end to end 1.89535 ms, enqueue 0.230185 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977966 ms - Host latency: 1.21872 ms (end to end 1.89306 ms, enqueue 0.232272 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976773 ms - Host latency: 1.2133 ms (end to end 1.89452 ms, enqueue 0.232904 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977472 ms - Host latency: 1.21331 ms (end to end 1.8959 ms, enqueue 0.232712 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976343 ms - Host latency: 1.21727 ms (end to end 1.8921 ms, enqueue 0.233862 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.9793 ms - Host latency: 1.22074 ms (end to end 1.89916 ms, enqueue 0.235098 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.980939 ms - Host latency: 1.23263 ms (end to end 1.90335 ms, enqueue 0.247711 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.995578 ms - Host latency: 1.23914 ms (end to end 1.93645 ms, enqueue 0.236548 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976843 ms - Host latency: 1.22134 ms (end to end 1.89478 ms, enqueue 0.240387 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977512 ms - Host latency: 1.21805 ms (end to end 1.89796 ms, enqueue 0.240692 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976877 ms - Host latency: 1.21883 ms (end to end 1.87941 ms, enqueue 0.239081 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978183 ms - Host latency: 1.21906 ms (end to end 1.89658 ms, enqueue 0.23855 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977536 ms - Host latency: 1.23011 ms (end to end 1.73327 ms, enqueue 0.248105 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.975723 ms - Host latency: 1.22589 ms (end to end 1.62321 ms, enqueue 0.242621 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976816 ms - Host latency: 1.22885 ms (end to end 1.75202 ms, enqueue 0.249472 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977316 ms - Host latency: 1.22369 ms (end to end 1.89966 ms, enqueue 0.238507 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97825 ms - Host latency: 1.22346 ms (end to end 1.9003 ms, enqueue 0.239133 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977502 ms - Host latency: 1.22109 ms (end to end 1.90055 ms, enqueue 0.240305 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977618 ms - Host latency: 1.22109 ms (end to end 1.89935 ms, enqueue 0.237329 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978503 ms - Host latency: 1.22327 ms (end to end 1.89966 ms, enqueue 0.237347 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97818 ms - Host latency: 1.22626 ms (end to end 1.89887 ms, enqueue 0.237604 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97627 ms - Host latency: 1.22172 ms (end to end 1.89543 ms, enqueue 0.238947 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01993 ms - Host latency: 1.31578 ms (end to end 1.95909 ms, enqueue 0.318243 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977234 ms - Host latency: 1.21835 ms (end to end 1.89326 ms, enqueue 0.237634 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978253 ms - Host latency: 1.22145 ms (end to end 1.89655 ms, enqueue 0.2375 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979456 ms - Host latency: 1.21932 ms (end to end 1.90225 ms, enqueue 0.238782 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.980322 ms - Host latency: 1.22047 ms (end to end 1.90373 ms, enqueue 0.235767 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.9776 ms - Host latency: 1.21816 ms (end to end 1.90022 ms, enqueue 0.235583 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976617 ms - Host latency: 1.21686 ms (end to end 1.89538 ms, enqueue 0.235736 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976514 ms - Host latency: 1.21622 ms (end to end 1.89669 ms, enqueue 0.234393 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978308 ms - Host latency: 1.21797 ms (end to end 1.89904 ms, enqueue 0.236243 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978723 ms - Host latency: 1.2184 ms (end to end 1.90187 ms, enqueue 0.236127 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01483 ms - Host latency: 1.28349 ms (end to end 1.96436 ms, enqueue 0.275507 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977429 ms - Host latency: 1.21796 ms (end to end 1.89714 ms, enqueue 0.237311 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.980078 ms - Host latency: 1.23145 ms (end to end 1.89193 ms, enqueue 0.262036 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97735 ms - Host latency: 1.21595 ms (end to end 1.89607 ms, enqueue 0.23457 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977441 ms - Host latency: 1.2162 ms (end to end 1.89404 ms, enqueue 0.236206 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976031 ms - Host latency: 1.21419 ms (end to end 1.83188 ms, enqueue 0.235052 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979236 ms - Host latency: 1.21788 ms (end to end 1.90002 ms, enqueue 0.233813 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977411 ms - Host latency: 1.21689 ms (end to end 1.8965 ms, enqueue 0.23642 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978601 ms - Host latency: 1.21722 ms (end to end 1.89765 ms, enqueue 0.234869 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978229 ms - Host latency: 1.21655 ms (end to end 1.89508 ms, enqueue 0.234784 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.998987 ms - Host latency: 1.24108 ms (end to end 1.91631 ms, enqueue 0.235083 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.0168 ms - Host latency: 1.29002 ms (end to end 1.9889 ms, enqueue 0.312628 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976129 ms - Host latency: 1.2196 ms (end to end 1.88726 ms, enqueue 0.263495 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976801 ms - Host latency: 1.21605 ms (end to end 1.89368 ms, enqueue 0.237726 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978076 ms - Host latency: 1.21598 ms (end to end 1.89707 ms, enqueue 0.235577 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97796 ms - Host latency: 1.21644 ms (end to end 1.88978 ms, enqueue 0.234302 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978546 ms - Host latency: 1.21774 ms (end to end 1.89767 ms, enqueue 0.236261 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977911 ms - Host latency: 1.21638 ms (end to end 1.89675 ms, enqueue 0.233838 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977582 ms - Host latency: 1.21659 ms (end to end 1.89477 ms, enqueue 0.235657 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977673 ms - Host latency: 1.21576 ms (end to end 1.89716 ms, enqueue 0.23277 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.996381 ms - Host latency: 1.27003 ms (end to end 1.92039 ms, enqueue 0.254565 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01772 ms - Host latency: 1.2838 ms (end to end 1.77963 ms, enqueue 0.249329 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976599 ms - Host latency: 1.2236 ms (end to end 1.70275 ms, enqueue 0.239178 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976215 ms - Host latency: 1.22212 ms (end to end 1.65825 ms, enqueue 0.238409 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977136 ms - Host latency: 1.22339 ms (end to end 1.6756 ms, enqueue 0.240228 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978333 ms - Host latency: 1.22569 ms (end to end 1.83521 ms, enqueue 0.241034 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97793 ms - Host latency: 1.22366 ms (end to end 1.89666 ms, enqueue 0.241876 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978192 ms - Host latency: 1.22477 ms (end to end 1.89545 ms, enqueue 0.239648 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978247 ms - Host latency: 1.22432 ms (end to end 1.89788 ms, enqueue 0.24057 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01572 ms - Host latency: 1.28726 ms (end to end 1.96994 ms, enqueue 0.265704 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.998413 ms - Host latency: 1.27975 ms (end to end 1.93195 ms, enqueue 0.270526 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978149 ms - Host latency: 1.22487 ms (end to end 1.88192 ms, enqueue 0.246088 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.975769 ms - Host latency: 1.21429 ms (end to end 1.89293 ms, enqueue 0.235315 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979285 ms - Host latency: 1.21842 ms (end to end 1.89975 ms, enqueue 0.234985 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977045 ms - Host latency: 1.21531 ms (end to end 1.89411 ms, enqueue 0.23598 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.975598 ms - Host latency: 1.21468 ms (end to end 1.89241 ms, enqueue 0.238739 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976196 ms - Host latency: 1.21452 ms (end to end 1.89294 ms, enqueue 0.235352 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977979 ms - Host latency: 1.21697 ms (end to end 1.89713 ms, enqueue 0.235583 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976587 ms - Host latency: 1.21586 ms (end to end 1.88981 ms, enqueue 0.235632 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977734 ms - Host latency: 1.22402 ms (end to end 1.82598 ms, enqueue 0.25675 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.996313 ms - Host latency: 1.25062 ms (end to end 1.81395 ms, enqueue 0.270056 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979846 ms - Host latency: 1.22341 ms (end to end 1.89008 ms, enqueue 0.260754 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976306 ms - Host latency: 1.21471 ms (end to end 1.89286 ms, enqueue 0.233655 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977405 ms - Host latency: 1.21563 ms (end to end 1.89569 ms, enqueue 0.237085 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976819 ms - Host latency: 1.21559 ms (end to end 1.82697 ms, enqueue 0.236218 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976929 ms - Host latency: 1.21569 ms (end to end 1.52814 ms, enqueue 0.234363 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977783 ms - Host latency: 1.2171 ms (end to end 1.74126 ms, enqueue 0.232495 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977124 ms - Host latency: 1.21973 ms (end to end 1.76309 ms, enqueue 0.232983 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978418 ms - Host latency: 1.21964 ms (end to end 1.70939 ms, enqueue 0.237622 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977832 ms - Host latency: 1.23403 ms (end to end 1.77688 ms, enqueue 0.241077 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01628 ms - Host latency: 1.26188 ms (end to end 1.96656 ms, enqueue 0.247644 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.996692 ms - Host latency: 1.25027 ms (end to end 1.93295 ms, enqueue 0.247876 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977429 ms - Host latency: 1.21547 ms (end to end 1.82919 ms, enqueue 0.254395 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977112 ms - Host latency: 1.21586 ms (end to end 1.82964 ms, enqueue 0.235413 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976807 ms - Host latency: 1.21567 ms (end to end 1.8939 ms, enqueue 0.236584 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977222 ms - Host latency: 1.21569 ms (end to end 1.89109 ms, enqueue 0.236548 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978455 ms - Host latency: 1.21709 ms (end to end 1.89775 ms, enqueue 0.237073 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.975732 ms - Host latency: 1.21359 ms (end to end 1.82997 ms, enqueue 0.235217 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977124 ms - Host latency: 1.2157 ms (end to end 1.897 ms, enqueue 0.236353 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978174 ms - Host latency: 1.21766 ms (end to end 1.89556 ms, enqueue 0.235681 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978894 ms - Host latency: 1.22889 ms (end to end 1.88813 ms, enqueue 0.260132 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01594 ms - Host latency: 1.28745 ms (end to end 1.9411 ms, enqueue 0.276001 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97821 ms - Host latency: 1.21622 ms (end to end 1.89537 ms, enqueue 0.234717 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976892 ms - Host latency: 1.21523 ms (end to end 1.89486 ms, enqueue 0.237463 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978638 ms - Host latency: 1.21721 ms (end to end 1.89884 ms, enqueue 0.233765 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977795 ms - Host latency: 1.22261 ms (end to end 1.89454 ms, enqueue 0.239087 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979846 ms - Host latency: 1.22308 ms (end to end 1.89832 ms, enqueue 0.236243 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979163 ms - Host latency: 1.21884 ms (end to end 1.90118 ms, enqueue 0.235889 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977734 ms - Host latency: 1.2161 ms (end to end 1.8949 ms, enqueue 0.233838 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978052 ms - Host latency: 1.21681 ms (end to end 1.89696 ms, enqueue 0.234497 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.981592 ms - Host latency: 1.24752 ms (end to end 1.88593 ms, enqueue 0.2797 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01259 ms - Host latency: 1.2559 ms (end to end 1.96262 ms, enqueue 0.244824 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97793 ms - Host latency: 1.22213 ms (end to end 1.89198 ms, enqueue 0.238989 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977283 ms - Host latency: 1.21792 ms (end to end 1.89391 ms, enqueue 0.236646 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979541 ms - Host latency: 1.21946 ms (end to end 1.89714 ms, enqueue 0.240308 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97655 ms - Host latency: 1.21571 ms (end to end 1.89362 ms, enqueue 0.233081 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978467 ms - Host latency: 1.21714 ms (end to end 1.89612 ms, enqueue 0.23551 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.975671 ms - Host latency: 1.21383 ms (end to end 1.71956 ms, enqueue 0.249548 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977771 ms - Host latency: 1.22308 ms (end to end 1.81736 ms, enqueue 0.236487 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976501 ms - Host latency: 1.22006 ms (end to end 1.72338 ms, enqueue 0.239026 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.993506 ms - Host latency: 1.25217 ms (end to end 1.7165 ms, enqueue 0.24469 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.975452 ms - Host latency: 1.22065 ms (end to end 1.60186 ms, enqueue 0.269934 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97832 ms - Host latency: 1.22478 ms (end to end 1.74113 ms, enqueue 0.239063 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978137 ms - Host latency: 1.22463 ms (end to end 1.85117 ms, enqueue 0.243542 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978906 ms - Host latency: 1.22617 ms (end to end 1.86768 ms, enqueue 0.242371 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979053 ms - Host latency: 1.22537 ms (end to end 1.85526 ms, enqueue 0.243298 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979553 ms - Host latency: 1.22665 ms (end to end 1.85222 ms, enqueue 0.245398 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979431 ms - Host latency: 1.22906 ms (end to end 1.74127 ms, enqueue 0.242676 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.02916 ms - Host latency: 1.34418 ms (end to end 1.69971 ms, enqueue 0.274194 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977686 ms - Host latency: 1.23038 ms (end to end 1.74279 ms, enqueue 0.240723 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.99502 ms - Host latency: 1.24348 ms (end to end 1.7304 ms, enqueue 0.256311 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978821 ms - Host latency: 1.22609 ms (end to end 1.89656 ms, enqueue 0.241772 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977344 ms - Host latency: 1.22341 ms (end to end 1.82979 ms, enqueue 0.238611 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979077 ms - Host latency: 1.22611 ms (end to end 1.89706 ms, enqueue 0.238916 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979553 ms - Host latency: 1.22593 ms (end to end 1.89608 ms, enqueue 0.239429 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.0145 ms - Host latency: 1.29458 ms (end to end 1.96841 ms, enqueue 0.26731 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977795 ms - Host latency: 1.22159 ms (end to end 1.88739 ms, enqueue 0.243604 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976904 ms - Host latency: 1.21516 ms (end to end 1.89398 ms, enqueue 0.234729 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977795 ms - Host latency: 1.21626 ms (end to end 1.89537 ms, enqueue 0.234924 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977148 ms - Host latency: 1.2162 ms (end to end 1.89658 ms, enqueue 0.236475 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978345 ms - Host latency: 1.2166 ms (end to end 1.89602 ms, enqueue 0.233972 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976135 ms - Host latency: 1.21497 ms (end to end 1.89423 ms, enqueue 0.234436 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97854 ms - Host latency: 1.21753 ms (end to end 1.89734 ms, enqueue 0.234216 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97804 ms - Host latency: 1.21616 ms (end to end 1.89619 ms, enqueue 0.232825 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977295 ms - Host latency: 1.21569 ms (end to end 1.89333 ms, enqueue 0.23407 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01102 ms - Host latency: 1.25491 ms (end to end 1.84255 ms, enqueue 0.250916 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.996301 ms - Host latency: 1.25995 ms (end to end 1.8646 ms, enqueue 0.265344 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976038 ms - Host latency: 1.21663 ms (end to end 1.70945 ms, enqueue 0.233289 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976465 ms - Host latency: 1.21404 ms (end to end 1.57291 ms, enqueue 0.245764 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976367 ms - Host latency: 1.21659 ms (end to end 1.60513 ms, enqueue 0.294373 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976318 ms - Host latency: 1.21467 ms (end to end 1.8903 ms, enqueue 0.278259 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97771 ms - Host latency: 1.21655 ms (end to end 1.89304 ms, enqueue 0.277283 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976855 ms - Host latency: 1.21508 ms (end to end 1.76957 ms, enqueue 0.275452 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977148 ms - Host latency: 1.21501 ms (end to end 1.89218 ms, enqueue 0.278711 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979126 ms - Host latency: 1.22384 ms (end to end 1.8896 ms, enqueue 0.281775 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01638 ms - Host latency: 1.30081 ms (end to end 1.96792 ms, enqueue 0.318066 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.980017 ms - Host latency: 1.22957 ms (end to end 1.88113 ms, enqueue 0.281995 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977991 ms - Host latency: 1.21635 ms (end to end 1.89025 ms, enqueue 0.278918 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977893 ms - Host latency: 1.2171 ms (end to end 1.8933 ms, enqueue 0.277161 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979517 ms - Host latency: 1.21809 ms (end to end 1.89972 ms, enqueue 0.272253 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979211 ms - Host latency: 1.21846 ms (end to end 1.90422 ms, enqueue 0.271692 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977185 ms - Host latency: 1.21649 ms (end to end 1.89583 ms, enqueue 0.277112 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977429 ms - Host latency: 1.21735 ms (end to end 1.89829 ms, enqueue 0.276501 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979126 ms - Host latency: 1.21812 ms (end to end 1.90253 ms, enqueue 0.273425 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976343 ms - Host latency: 1.21936 ms (end to end 1.8969 ms, enqueue 0.272217 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01543 ms - Host latency: 1.26233 ms (end to end 1.97307 ms, enqueue 0.274585 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.99436 ms - Host latency: 1.23938 ms (end to end 1.93225 ms, enqueue 0.270483 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979346 ms - Host latency: 1.21797 ms (end to end 1.90149 ms, enqueue 0.275244 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979639 ms - Host latency: 1.21814 ms (end to end 1.90388 ms, enqueue 0.270728 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978516 ms - Host latency: 1.21709 ms (end to end 1.90173 ms, enqueue 0.268018 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976978 ms - Host latency: 1.21565 ms (end to end 1.73389 ms, enqueue 0.266089 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977441 ms - Host latency: 1.21555 ms (end to end 1.697 ms, enqueue 0.250806 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979395 ms - Host latency: 1.23042 ms (end to end 1.82031 ms, enqueue 0.254761 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977808 ms - Host latency: 1.23604 ms (end to end 1.81331 ms, enqueue 0.262183 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978003 ms - Host latency: 1.24072 ms (end to end 1.69839 ms, enqueue 0.256372 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979248 ms - Host latency: 1.24334 ms (end to end 1.90063 ms, enqueue 0.265405 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01199 ms - Host latency: 1.2739 ms (end to end 1.97148 ms, enqueue 0.263818 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978198 ms - Host latency: 1.22637 ms (end to end 1.90203 ms, enqueue 0.267188 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977002 ms - Host latency: 1.21484 ms (end to end 1.76519 ms, enqueue 0.269971 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97959 ms - Host latency: 1.21829 ms (end to end 1.90493 ms, enqueue 0.271484 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.980176 ms - Host latency: 1.21907 ms (end to end 1.90806 ms, enqueue 0.272266 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.08718 ms - Host latency: 1.32859 ms (end to end 1.93801 ms, enqueue 0.507764 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978809 ms - Host latency: 1.2177 ms (end to end 1.90063 ms, enqueue 0.247949 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977075 ms - Host latency: 1.21563 ms (end to end 1.89597 ms, enqueue 0.239673 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977856 ms - Host latency: 1.21868 ms (end to end 1.89011 ms, enqueue 0.286084 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976929 ms - Host latency: 1.21716 ms (end to end 1.81331 ms, enqueue 0.279395 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01575 ms - Host latency: 1.26057 ms (end to end 1.96919 ms, enqueue 0.256201 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97832 ms - Host latency: 1.22527 ms (end to end 1.89592 ms, enqueue 0.236523 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977051 ms - Host latency: 1.22439 ms (end to end 1.89736 ms, enqueue 0.238525 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977905 ms - Host latency: 1.22373 ms (end to end 1.89558 ms, enqueue 0.237329 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979028 ms - Host latency: 1.22554 ms (end to end 1.89941 ms, enqueue 0.236621 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97749 ms - Host latency: 1.22419 ms (end to end 1.89531 ms, enqueue 0.236646 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977515 ms - Host latency: 1.22466 ms (end to end 1.897 ms, enqueue 0.237231 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976807 ms - Host latency: 1.22366 ms (end to end 1.89412 ms, enqueue 0.236719 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01492 ms - Host latency: 1.27861 ms (end to end 1.95198 ms, enqueue 0.356567 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978296 ms - Host latency: 1.22288 ms (end to end 1.88372 ms, enqueue 0.296289 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977246 ms - Host latency: 1.22263 ms (end to end 1.8928 ms, enqueue 0.243872 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977466 ms - Host latency: 1.21677 ms (end to end 1.89409 ms, enqueue 0.236816 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97749 ms - Host latency: 1.2158 ms (end to end 1.89678 ms, enqueue 0.234766 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978809 ms - Host latency: 1.21741 ms (end to end 1.89895 ms, enqueue 0.235254 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97688 ms - Host latency: 1.2167 ms (end to end 1.89736 ms, enqueue 0.23645 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979492 ms - Host latency: 1.21868 ms (end to end 1.90098 ms, enqueue 0.236523 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978687 ms - Host latency: 1.21755 ms (end to end 1.86675 ms, enqueue 0.239893 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977637 ms - Host latency: 1.21794 ms (end to end 1.8343 ms, enqueue 0.235547 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01731 ms - Host latency: 1.26846 ms (end to end 1.96506 ms, enqueue 0.286401 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977393 ms - Host latency: 1.23704 ms (end to end 1.79949 ms, enqueue 0.295142 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976587 ms - Host latency: 1.21509 ms (end to end 1.68567 ms, enqueue 0.251196 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977319 ms - Host latency: 1.21594 ms (end to end 1.80945 ms, enqueue 0.268164 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979517 ms - Host latency: 1.21824 ms (end to end 1.87407 ms, enqueue 0.239136 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978223 ms - Host latency: 1.21663 ms (end to end 1.9021 ms, enqueue 0.237964 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977979 ms - Host latency: 1.21689 ms (end to end 1.90098 ms, enqueue 0.236377 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979492 ms - Host latency: 1.21841 ms (end to end 1.90198 ms, enqueue 0.235352 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978589 ms - Host latency: 1.21699 ms (end to end 1.90078 ms, enqueue 0.236523 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97915 ms - Host latency: 1.22046 ms (end to end 1.89412 ms, enqueue 0.306763 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976636 ms - Host latency: 1.21685 ms (end to end 1.81921 ms, enqueue 0.27876 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.03511 ms - Host latency: 1.32407 ms (end to end 1.98335 ms, enqueue 0.334912 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976343 ms - Host latency: 1.21421 ms (end to end 1.89282 ms, enqueue 0.264746 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978198 ms - Host latency: 1.21589 ms (end to end 1.90122 ms, enqueue 0.235767 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978198 ms - Host latency: 1.2166 ms (end to end 1.90095 ms, enqueue 0.23623 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97793 ms - Host latency: 1.21582 ms (end to end 1.899 ms, enqueue 0.234937 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976318 ms - Host latency: 1.21436 ms (end to end 1.89634 ms, enqueue 0.233569 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97727 ms - Host latency: 1.21704 ms (end to end 1.89536 ms, enqueue 0.235596 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977686 ms - Host latency: 1.21599 ms (end to end 1.89675 ms, enqueue 0.23457 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977515 ms - Host latency: 1.21833 ms (end to end 1.88484 ms, enqueue 0.2698 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978662 ms - Host latency: 1.22344 ms (end to end 1.89395 ms, enqueue 0.285937 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.0116 ms - Host latency: 1.26543 ms (end to end 1.93962 ms, enqueue 0.305957 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978857 ms - Host latency: 1.21802 ms (end to end 1.89758 ms, enqueue 0.23606 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978882 ms - Host latency: 1.2175 ms (end to end 1.89844 ms, enqueue 0.234595 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97915 ms - Host latency: 1.21787 ms (end to end 1.90161 ms, enqueue 0.235425 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97666 ms - Host latency: 1.21575 ms (end to end 1.83181 ms, enqueue 0.235596 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.980151 ms - Host latency: 1.21929 ms (end to end 1.90393 ms, enqueue 0.235571 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977539 ms - Host latency: 1.2167 ms (end to end 1.8998 ms, enqueue 0.235767 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979077 ms - Host latency: 1.21736 ms (end to end 1.90437 ms, enqueue 0.235327 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977979 ms - Host latency: 1.21931 ms (end to end 1.89382 ms, enqueue 0.249243 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977856 ms - Host latency: 1.21953 ms (end to end 1.89355 ms, enqueue 0.278149 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01223 ms - Host latency: 1.25896 ms (end to end 1.96064 ms, enqueue 0.282153 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.97688 ms - Host latency: 1.22351 ms (end to end 1.89287 ms, enqueue 0.237012 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978955 ms - Host latency: 1.22612 ms (end to end 1.89661 ms, enqueue 0.237183 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977954 ms - Host latency: 1.22361 ms (end to end 1.89873 ms, enqueue 0.238721 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977222 ms - Host latency: 1.22427 ms (end to end 1.89768 ms, enqueue 0.23772 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977075 ms - Host latency: 1.2231 ms (end to end 1.89783 ms, enqueue 0.236401 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977344 ms - Host latency: 1.22334 ms (end to end 1.89646 ms, enqueue 0.236548 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978003 ms - Host latency: 1.2249 ms (end to end 1.89885 ms, enqueue 0.237036 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979932 ms - Host latency: 1.22715 ms (end to end 1.88684 ms, enqueue 0.253955 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.981104 ms - Host latency: 1.24021 ms (end to end 1.74717 ms, enqueue 0.294507 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01538 ms - Host latency: 1.26423 ms (end to end 1.95625 ms, enqueue 0.413623 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.975757 ms - Host latency: 1.21299 ms (end to end 1.59119 ms, enqueue 0.259937 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976221 ms - Host latency: 1.21284 ms (end to end 1.6886 ms, enqueue 0.239087 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.1116 ms - Host latency: 1.35181 ms (end to end 1.81748 ms, enqueue 0.469434 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978174 ms - Host latency: 1.21768 ms (end to end 1.89836 ms, enqueue 0.237329 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979321 ms - Host latency: 1.21833 ms (end to end 1.90083 ms, enqueue 0.235791 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977612 ms - Host latency: 1.21631 ms (end to end 1.89971 ms, enqueue 0.235693 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979663 ms - Host latency: 1.22192 ms (end to end 1.89771 ms, enqueue 0.241992 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.984497 ms - Host latency: 1.23838 ms (end to end 1.89236 ms, enqueue 0.280054 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.01667 ms - Host latency: 1.27043 ms (end to end 1.95798 ms, enqueue 0.360913 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977319 ms - Host latency: 1.21953 ms (end to end 1.88052 ms, enqueue 0.250317 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979346 ms - Host latency: 1.22764 ms (end to end 1.89832 ms, enqueue 0.236597 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977319 ms - Host latency: 1.22986 ms (end to end 1.89399 ms, enqueue 0.23606 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977515 ms - Host latency: 1.22129 ms (end to end 1.89744 ms, enqueue 0.238086 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977588 ms - Host latency: 1.21924 ms (end to end 1.89771 ms, enqueue 0.236646 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.980884 ms - Host latency: 1.21958 ms (end to end 1.90505 ms, enqueue 0.234326 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978369 ms - Host latency: 1.21799 ms (end to end 1.90215 ms, enqueue 0.23479 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977881 ms - Host latency: 1.22283 ms (end to end 1.89485 ms, enqueue 0.243213 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.982983 ms - Host latency: 1.23242 ms (end to end 1.87617 ms, enqueue 0.316235 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.02632 ms - Host latency: 1.36135 ms (end to end 1.9624 ms, enqueue 0.323242 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.99502 ms - Host latency: 1.23584 ms (end to end 1.92891 ms, enqueue 0.245068 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978027 ms - Host latency: 1.22473 ms (end to end 1.89766 ms, enqueue 0.241235 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.98291 ms - Host latency: 1.23066 ms (end to end 1.90752 ms, enqueue 0.237769 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 1.00188 ms - Host latency: 1.26846 ms (end to end 1.88223 ms, enqueue 0.256934 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976636 ms - Host latency: 1.2167 ms (end to end 1.79084 ms, enqueue 0.23689 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.978467 ms - Host latency: 1.21763 ms (end to end 1.72026 ms, enqueue 0.237134 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977197 ms - Host latency: 1.21611 ms (end to end 1.80862 ms, enqueue 0.234961 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979175 ms - Host latency: 1.22078 ms (end to end 1.69312 ms, enqueue 0.245996 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.976782 ms - Host latency: 1.22356 ms (end to end 1.6866 ms, enqueue 0.290479 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.979224 ms - Host latency: 1.22642 ms (end to end 1.8967 ms, enqueue 0.262988 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977637 ms - Host latency: 1.21841 ms (end to end 1.89739 ms, enqueue 0.237744 ms)\n","[07/22/2022-13:12:35] [I] Average on 10 runs - GPU latency: 0.977466 ms - Host latency: 1.2166 ms (end to end 1.8321 ms, enqueue 0.234717 ms)\n","[07/22/2022-13:12:35] [I] \n","[07/22/2022-13:12:35] [I] === Performance summary ===\n","[07/22/2022-13:12:35] [I] Throughput: 936.174 qps\n","[07/22/2022-13:12:35] [I] Latency: min = 1.20532 ms, max = 2.55518 ms, mean = 1.22779 ms, median = 1.21875 ms, percentile(99%) = 1.42358 ms\n","[07/22/2022-13:12:35] [I] End-to-End Host Latency: min = 1.22144 ms, max = 3.11182 ms, mean = 1.86958 ms, median = 1.89575 ms, percentile(99%) = 2.11292 ms\n","[07/22/2022-13:12:35] [I] Enqueue Time: min = 0.221436 ms, max = 2.69019 ms, mean = 0.25205 ms, median = 0.237732 ms, percentile(99%) = 0.409058 ms\n","[07/22/2022-13:12:35] [I] H2D Latency: min = 0.224274 ms, max = 1.12939 ms, mean = 0.236128 ms, median = 0.230957 ms, percentile(99%) = 0.299744 ms\n","[07/22/2022-13:12:35] [I] GPU Compute Time: min = 0.970093 ms, max = 2.31372 ms, mean = 0.982895 ms, median = 0.977661 ms, percentile(99%) = 1.16284 ms\n","[07/22/2022-13:12:35] [I] D2H Latency: min = 0.00634766 ms, max = 0.0205078 ms, mean = 0.00876877 ms, median = 0.00878906 ms, percentile(99%) = 0.0102539 ms\n","[07/22/2022-13:12:35] [I] Total Host Walltime: 3.00372 s\n","[07/22/2022-13:12:35] [I] Total GPU Compute Time: 2.7639 s\n","[07/22/2022-13:12:35] [I] Explanations of the performance metrics are printed in the verbose logs.\n","[07/22/2022-13:12:35] [I] \n","&&&& PASSED TensorRT.trtexec [TensorRT v8205] # trtexec --onnx=./triton_model_repository/resnet50_onnx/1/model.onnx --explicitBatch --workspace=16382 --optShapes=input:8x3x224x224 --maxShapes=input:128x3x224x224 --minShapes=input:1x3x224x224 --saveEngine=./triton_model_repository/resnet50_trt_fp16/1/model.plan --fp16\n"]}],"source":["!trtexec \\\n","  --onnx=$ONNX_MODEL_PATH \\\n","  --explicitBatch \\\n","  --workspace=16382 \\\n","  --optShapes=input:8x3x224x224 \\\n","  --maxShapes=input:128x3x224x224 \\\n","  --minShapes=input:1x3x224x224 \\\n","  --saveEngine=$TRT_MODEL_PATH_FP16 --fp16"]},{"cell_type":"markdown","id":"6a4a9085","metadata":{"id":"6a4a9085"},"source":["**if CHANNEL_LAST**\n","\n","\n","`!trtexec \\\n","  --onnx=$ONNX_MODEL_PATH \\\n","  --explicitBatch \\\n","  --workspace=16382 \\\n","  --optShapes=input:8x224x224x3 \\\n","  --maxShapes=input:128x224x224x3 \\\n","  --minShapes=input:1x224x224x3 \\\n","  --saveEngine=$TRT_MODEL_PATH' --fp16`"]},{"cell_type":"markdown","id":"7a980135","metadata":{"id":"7a980135"},"source":["Test the TensorRT model for dummy data"]},{"cell_type":"code","execution_count":null,"id":"e772c7dd","metadata":{"id":"e772c7dd","outputId":"eb4441e3-586d-46ab-c2ad-78bf1b236249"},"outputs":[{"name":"stdout","output_type":"stream","text":["&&&& RUNNING TensorRT.trtexec [TensorRT v8205] # trtexec --loadEngine=/workspace/nvidia/triton_model_repository/resnet50_trt_fp32/1/model.plan --shapes=input:8x3x224x224\n","[07/22/2022-12:01:55] [I] === Model Options ===\n","[07/22/2022-12:01:55] [I] Format: *\n","[07/22/2022-12:01:55] [I] Model: \n","[07/22/2022-12:01:55] [I] Output:\n","[07/22/2022-12:01:55] [I] === Build Options ===\n","[07/22/2022-12:01:55] [I] Max batch: explicit batch\n","[07/22/2022-12:01:55] [I] Workspace: 16 MiB\n","[07/22/2022-12:01:55] [I] minTiming: 1\n","[07/22/2022-12:01:55] [I] avgTiming: 8\n","[07/22/2022-12:01:55] [I] Precision: FP32\n","[07/22/2022-12:01:55] [I] Calibration: \n","[07/22/2022-12:01:55] [I] Refit: Disabled\n","[07/22/2022-12:01:55] [I] Sparsity: Disabled\n","[07/22/2022-12:01:55] [I] Safe mode: Disabled\n","[07/22/2022-12:01:55] [I] DirectIO mode: Disabled\n","[07/22/2022-12:01:55] [I] Restricted mode: Disabled\n","[07/22/2022-12:01:55] [I] Save engine: \n","[07/22/2022-12:01:55] [I] Load engine: /workspace/nvidia/triton_model_repository/resnet50_trt_fp32/1/model.plan\n","[07/22/2022-12:01:55] [I] Profiling verbosity: 0\n","[07/22/2022-12:01:55] [I] Tactic sources: Using default tactic sources\n","[07/22/2022-12:01:55] [I] timingCacheMode: local\n","[07/22/2022-12:01:55] [I] timingCacheFile: \n","[07/22/2022-12:01:55] [I] Input(s)s format: fp32:CHW\n","[07/22/2022-12:01:55] [I] Output(s)s format: fp32:CHW\n","[07/22/2022-12:01:55] [I] Input build shape: input=8x3x224x224+8x3x224x224+8x3x224x224\n","[07/22/2022-12:01:55] [I] Input calibration shapes: model\n","[07/22/2022-12:01:55] [I] === System Options ===\n","[07/22/2022-12:01:55] [I] Device: 0\n","[07/22/2022-12:01:55] [I] DLACore: \n","[07/22/2022-12:01:55] [I] Plugins:\n","[07/22/2022-12:01:55] [I] === Inference Options ===\n","[07/22/2022-12:01:55] [I] Batch: Explicit\n","[07/22/2022-12:01:55] [I] Input inference shape: input=8x3x224x224\n","[07/22/2022-12:01:55] [I] Iterations: 10\n","[07/22/2022-12:01:55] [I] Duration: 3s (+ 200ms warm up)\n","[07/22/2022-12:01:55] [I] Sleep time: 0ms\n","[07/22/2022-12:01:55] [I] Idle time: 0ms\n","[07/22/2022-12:01:55] [I] Streams: 1\n","[07/22/2022-12:01:55] [I] ExposeDMA: Disabled\n","[07/22/2022-12:01:55] [I] Data transfers: Enabled\n","[07/22/2022-12:01:55] [I] Spin-wait: Disabled\n","[07/22/2022-12:01:55] [I] Multithreading: Disabled\n","[07/22/2022-12:01:55] [I] CUDA Graph: Disabled\n","[07/22/2022-12:01:55] [I] Separate profiling: Disabled\n","[07/22/2022-12:01:55] [I] Time Deserialize: Disabled\n","[07/22/2022-12:01:55] [I] Time Refit: Disabled\n","[07/22/2022-12:01:55] [I] Skip inference: Disabled\n","[07/22/2022-12:01:55] [I] Inputs:\n","[07/22/2022-12:01:55] [I] === Reporting Options ===\n","[07/22/2022-12:01:55] [I] Verbose: Disabled\n","[07/22/2022-12:01:55] [I] Averages: 10 inferences\n","[07/22/2022-12:01:55] [I] Percentile: 99\n","[07/22/2022-12:01:55] [I] Dump refittable layers:Disabled\n","[07/22/2022-12:01:55] [I] Dump output: Disabled\n","[07/22/2022-12:01:55] [I] Profile: Disabled\n","[07/22/2022-12:01:55] [I] Export timing to JSON file: \n","[07/22/2022-12:01:55] [I] Export output to JSON file: \n","[07/22/2022-12:01:55] [I] Export profile to JSON file: \n","[07/22/2022-12:01:55] [I] \n","[07/22/2022-12:01:55] [I] === Device Information ===\n","[07/22/2022-12:01:55] [I] Selected Device: Tesla V100-PCIE-16GB\n","[07/22/2022-12:01:55] [I] Compute Capability: 7.0\n","[07/22/2022-12:01:55] [I] SMs: 80\n","[07/22/2022-12:01:55] [I] Compute Clock Rate: 1.38 GHz\n","[07/22/2022-12:01:55] [I] Device Global Memory: 16160 MiB\n","[07/22/2022-12:01:55] [I] Shared Memory per SM: 96 KiB\n","[07/22/2022-12:01:55] [I] Memory Bus Width: 4096 bits (ECC enabled)\n","[07/22/2022-12:01:55] [I] Memory Clock Rate: 0.877 GHz\n","[07/22/2022-12:01:55] [I] \n","[07/22/2022-12:01:55] [I] TensorRT version: 8.2.5\n","[07/22/2022-12:01:55] [I] [TRT] [MemUsageChange] Init CUDA: CPU +277, GPU +0, now: CPU 407, GPU 4536 (MiB)\n","[07/22/2022-12:01:55] [I] [TRT] Loaded engine size: 118 MiB\n","[07/22/2022-12:01:56] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +370, GPU +172, now: CPU 778, GPU 4826 (MiB)\n","[07/22/2022-12:01:56] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +118, GPU +54, now: CPU 896, GPU 4880 (MiB)\n","[07/22/2022-12:01:56] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +117, now: CPU 0, GPU 117 (MiB)\n","[07/22/2022-12:01:56] [I] Engine loaded in 1.57737 sec.\n","[07/22/2022-12:01:56] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 778, GPU 4872 (MiB)\n","[07/22/2022-12:01:56] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 778, GPU 4880 (MiB)\n","[07/22/2022-12:01:56] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1094, now: CPU 0, GPU 1211 (MiB)\n","[07/22/2022-12:01:56] [I] Using random values for input input\n","[07/22/2022-12:01:56] [I] Created input binding for input with dimensions 8x3x224x224\n","[07/22/2022-12:01:56] [I] Using random values for output output\n","[07/22/2022-12:01:56] [I] Created output binding for output with dimensions 8x2\n","[07/22/2022-12:01:56] [I] Starting inference\n","[07/22/2022-12:02:00] [I] Warmup completed 13 queries over 200 ms\n","[07/22/2022-12:02:00] [I] Timing trace has 124 queries over 3.12332 s\n","[07/22/2022-12:02:00] [I] \n","[07/22/2022-12:02:00] [I] === Trace details ===\n","[07/22/2022-12:02:00] [I] Trace averages of 10 runs:\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 43.4614 ms - Host latency: 43.8934 ms (end to end 86.6146 ms, enqueue 0.95482 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 37.2516 ms - Host latency: 37.683 ms (end to end 76.0247 ms, enqueue 0.945593 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 25.2506 ms - Host latency: 25.6817 ms (end to end 50.4794 ms, enqueue 0.870673 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 26.3635 ms - Host latency: 26.7944 ms (end to end 49.1774 ms, enqueue 0.897083 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 23.9164 ms - Host latency: 24.3492 ms (end to end 47.8643 ms, enqueue 0.930945 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 25.7413 ms - Host latency: 26.1741 ms (end to end 47.7974 ms, enqueue 0.95553 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 19.9443 ms - Host latency: 20.377 ms (end to end 41.1212 ms, enqueue 1.07518 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 16.4763 ms - Host latency: 16.9129 ms (end to end 30.3422 ms, enqueue 1.12754 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 16.5297 ms - Host latency: 16.9659 ms (end to end 29.0519 ms, enqueue 0.874268 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 16.0228 ms - Host latency: 16.4556 ms (end to end 29.2215 ms, enqueue 0.872607 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 17.0212 ms - Host latency: 17.4544 ms (end to end 32.9858 ms, enqueue 1.18982 ms)\n","[07/22/2022-12:02:00] [I] Average on 10 runs - GPU latency: 22.1241 ms - Host latency: 22.5553 ms (end to end 40.2903 ms, enqueue 1.09639 ms)\n","[07/22/2022-12:02:00] [I] \n","[07/22/2022-12:02:00] [I] === Performance summary ===\n","[07/22/2022-12:02:00] [I] Throughput: 39.7014 qps\n","[07/22/2022-12:02:00] [I] Latency: min = 15.1885 ms, max = 48.0988 ms, mean = 25.1979 ms, median = 18.9666 ms, percentile(99%) = 47.1698 ms\n","[07/22/2022-12:02:00] [I] End-to-End Host Latency: min = 16.5286 ms, max = 90.0685 ms, mean = 47.9072 ms, median = 42.7571 ms, percentile(99%) = 89.8101 ms\n","[07/22/2022-12:02:00] [I] Enqueue Time: min = 0.734375 ms, max = 1.69897 ms, mean = 0.987074 ms, median = 0.97583 ms, percentile(99%) = 1.63379 ms\n","[07/22/2022-12:02:00] [I] H2D Latency: min = 0.404297 ms, max = 0.482422 ms, mean = 0.422373 ms, median = 0.420197 ms, percentile(99%) = 0.469971 ms\n","[07/22/2022-12:02:00] [I] GPU Compute Time: min = 14.6965 ms, max = 47.6662 ms, mean = 24.7651 ms, median = 18.5273 ms, percentile(99%) = 46.7395 ms\n","[07/22/2022-12:02:00] [I] D2H Latency: min = 0.00732422 ms, max = 0.0135498 ms, mean = 0.0104289 ms, median = 0.0102539 ms, percentile(99%) = 0.0133972 ms\n","[07/22/2022-12:02:00] [I] Total Host Walltime: 3.12332 s\n","[07/22/2022-12:02:00] [I] Total GPU Compute Time: 3.07088 s\n","[07/22/2022-12:02:00] [I] Explanations of the performance metrics are printed in the verbose logs.\n","[07/22/2022-12:02:00] [I] \n","&&&& PASSED TensorRT.trtexec [TensorRT v8205] # trtexec --loadEngine=/workspace/nvidia/triton_model_repository/resnet50_trt_fp32/1/model.plan --shapes=input:8x3x224x224\n"]}],"source":["!trtexec --loadEngine=$TRT_MODEL_PATH --shapes=input:8x3x224x224"]},{"cell_type":"code","execution_count":null,"id":"30e37a19","metadata":{"id":"30e37a19"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"colab":{"name":"model_conv.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}